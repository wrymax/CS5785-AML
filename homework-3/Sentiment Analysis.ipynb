{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! Python3\n",
    "# useful libs\n",
    "import numpy as np\n",
    "import operator\n",
    "import re\n",
    "import collections\n",
    "import nltk\n",
    "from difflib import ndiff\n",
    "import seaborn as sns\n",
    "import numpy.linalg as la\n",
    "import six\n",
    "\n",
    "# Preprocessing\n",
    "from gensim.utils import lemmatize\n",
    "\n",
    "# vectorizers\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (a) Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'encoding' is an invalid keyword argument for this function",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a3fb6f3c59bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0msentances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'yelp_labelled'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'amazon_cells_labelled'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'imdb_labelled'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/{}.txt'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#         sentances.append(unicode(st, \"utf-8\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'encoding' is an invalid keyword argument for this function"
     ]
    }
   ],
   "source": [
    "# yelp_sentance, yelp_score = [], []\n",
    "# for line in open('./data/yelp_labelled.txt'):\n",
    "#     st, sc = line.split(\"\\t\")\n",
    "#     yelp_sentance.append(unicode(st, \"utf-8\"))\n",
    "#     yelp_score.append(sc[0:-1])\n",
    "    \n",
    "# amazon_sentance, amazon_score = [], []\n",
    "# for line in open('./data/amazon_cells_labelled.txt'):\n",
    "#     st, sc = line.split(\"\\t\")\n",
    "#     amazon_sentance.append(st)\n",
    "#     amazon_score.append(sc[0:-1])\n",
    "\n",
    "# imdb_sentance, imdb_score = [], []\n",
    "# for line in open('./data/imdb_labelled.txt'):\n",
    "#     st, sc = line.split(\"\\t\")\n",
    "#     imdb_sentance.append(st)\n",
    "#     imdb_score.append(sc[0:-1])\n",
    "\n",
    "sentances, scores = [], []\n",
    "for file_name in ['yelp_labelled', 'amazon_cells_labelled', 'imdb_labelled']:    \n",
    "    for line in open('./data/{}.txt'.format(file_name), 'r', encoding='utf-8'):\n",
    "        st, sc = line.split(\"\\t\")\n",
    "#         sentances.append(unicode(st, \"utf-8\"))\n",
    "        sentances.append(st)\n",
    "#         sentances.append(str(st.encode()))\n",
    "        scores.append(sc[0:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count(0): 1500, count(1): 1500\n"
     ]
    }
   ],
   "source": [
    "counter = collections.Counter(scores)\n",
    "# amazon_counter = collections.Counter(amazon_score)\n",
    "# imdb_counter = collections.Counter(imdb_score)\n",
    "\n",
    "# print(\"Yelp count(0): {}, count(1): {}\".format(yelp_counter[\"0\"], yelp_counter[\"1\"]))\n",
    "# print(\"Amazon count(0): {}, count(1): {}\".format(amazon_counter[\"0\"], amazon_counter[\"1\"]))\n",
    "# print(\"Imdb count(0): {}, count(1): {}\".format(imdb_counter[\"0\"], imdb_counter[\"1\"]))\n",
    "print(\"count(0): {}, count(1): {}\".format(counter[\"0\"], counter[\"1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "Yes the labels are balanced. \n",
    "By reading each line of the training txt files, we got lists of sentences and scores. \n",
    "Using collection.Counter, we get to know the number of each label in the score lists. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (b) Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lowercase + strip punctuation + strip stopwords + lemmatization \n",
    "# yelp_np = [re.sub(r'[^\\w\\s]','',s) for s in yelp_nsw]\n",
    "sentences_processed = []\n",
    "for v in sentances:\n",
    "    _v = lemmatize(v)    \n",
    "    _v = [t.decode(\"utf-8\").split('/')[0] for t in _v]\n",
    "    sentences_processed.append(\" \".join(_v))\n",
    "# imdb_processed = [\" \".join(lemmatize(v)) for v in imdb_sentance]\n",
    "# amazon_processed = [\" \".join(lemmatize(v)) for v in amazon_sentance]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing explanations\n",
    "1) We should lowercase all of the words, because capitalized letters with make same words be treated as different ones.\n",
    "\n",
    "2) We should strip punctuations because they do not contribute to sentiment.\n",
    "\n",
    "3) Stop words are the most commonly occuring words which are not relevant in the context of the data and do not contribute any deeper meaning to the phrase. In this case contain no sentiment.\n",
    "\n",
    "4) We should do lemmatization.This process finds the base or dictionary form of the word known as the lemma. This is done through the use of vocabulary (dictionary importance of words) and morphological analysis (word structure and grammar relations). This normalization is similar to stemming but takes into account the context of the word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (c) Split Training and Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# yelp_train_x = yelp_processed[:400]\n",
    "# yelp_test_x = yelp_processed[400:]\n",
    "# amazon_train_x = amazon_processed[:400]\n",
    "# amazon_test_x = amazon_processed[400:]\n",
    "# imdb_train_x = imdb_processed[:400]\n",
    "# imdb_test_x = imdb_processed[400:]\n",
    "train_x = sentences_processed[:400] + sentences_processed[500:900] + sentences_processed[1000:1400]\n",
    "train_y = scores[:400] + scores[500:900] + scores[1000:1400]\n",
    "test_x = sentences_processed[400:500] + sentences_processed[900:1000] + sentences_processed[1400:1500]\n",
    "test_y = scores[400:500] + scores[900:1000] + scores[1400:1500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) Bag of Words\n",
    "Why should we vectorize training set first and then go through testing set?<br/>\n",
    "1) Here we should vectorize the training set standalone because testing set could contain words that are not contained in training set. <br/>\n",
    "2) We will vectorize testing set based on the feature vector generated by training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service be very prompt\n",
      "[[0 0 0 ... 0 0 0]]\n",
      "love place\n",
      "[[0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "train_vectorizer = CountVectorizer()\n",
    "# d.1. build a dictionary of unique words for training set\n",
    "train_x_bag = train_vectorizer.fit_transform(train_x).todense()\n",
    "test_vectorizer = CountVectorizer(vocabulary=train_vectorizer.get_feature_names())\n",
    "test_x_bag = test_vectorizer.fit_transform(test_x).todense()\n",
    "# d.2. Report feature vectors of 2 reviews\n",
    "print(train_x[10])\n",
    "print(train_x_bag[10])\n",
    "print(train_x[0])\n",
    "print(train_x_bag[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (e) Postprocessing strategy\n",
    "We choose L2 normalization as post-processing method, because:<br/>\n",
    "1) L2 presents the inner product of a vector on itself, representing the length of the vector<br/>\n",
    "2) The similarity between 2 vectors are calculated by their inner product, which is the format of L2<br/>\n",
    "3) So L2 would be an ideal way to constrain the value range of each feature into (0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# post-processing\n",
    "train_x_bag_normal = normalize(train_x_bag)\n",
    "test_x_bag_normal = normalize(test_x_bag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (f) Sentiment prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentiment_prediction(Train_X, Train_Y, Test_X, Test_Y):\n",
    "    # f.1 Logistic regression\n",
    "    lr_clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(Train_X, Train_Y)\n",
    "    lr_clf_score = lr_clf.score(Test_X, Test_Y)\n",
    "    print(\"Logistic regression accuracy: {}\".format(lr_clf_score))\n",
    "    \n",
    "    # f.2 Naive Bayes classifier\n",
    "    # Gaussian\n",
    "    gaussian_nb = GaussianNB()\n",
    "    gaussian_nb.fit(Train_X, Train_Y)\n",
    "    gaussian_nb_score = gaussian_nb.score(Test_X, Test_Y)\n",
    "    print(\"Accuracy of Naive Bayes Classifier with Gaussian prior: {}\".format(gaussian_nb_score))\n",
    "\n",
    "    # Bernoulli\n",
    "    b_nb = BernoulliNB()\n",
    "    b_nb.fit(Train_X, Train_Y)\n",
    "    b_nb_score = b_nb.score(Test_X, Test_Y)\n",
    "    print(\"Accuracy of Naive Bayes Classifier with Bernoulli prior: {}\".format(b_nb_score))\n",
    "    \n",
    "    return lr_clf_score, gaussian_nb_score, b_nb_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression accuracy: 0.78\n",
      "Accuracy of Naive Bayes Classifier with Gaussian prior: 0.7233333333333334\n",
      "Accuracy of Naive Bayes Classifier with Bernoulli prior: 0.7233333333333334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.78, 0.7233333333333334, 0.7233333333333334)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_prediction(train_x_bag_normal, train_y, test_x_bag_normal, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of classifiers:\n",
    "Logistic regression model is slightly better than Naive Bayes classifiers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words playing the most important roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 most important words: \n",
      "count(yummy) = 1851\n",
      "count(yum) = 1850\n",
      "count(yukon) = 1849\n",
      "count(yucky) = 1848\n",
      "count(yet) = 1847\n",
      "count(yelper) = 1846\n",
      "count(yellowtail) = 1845\n",
      "count(yellow) = 1844\n",
      "count(year) = 1843\n",
      "count(yama) = 1842\n"
     ]
    }
   ],
   "source": [
    "vocabulary = train_vectorizer.vocabulary_\n",
    "sorted_vocabulary = sorted(vocabulary.items(), key=operator.itemgetter(1), reverse=True)\n",
    "print(\"The top 10 most important words: \")\n",
    "for word in sorted_vocabulary[:10]:\n",
    "    print(\"count({}) = {}\".format(word[0], word[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (g) N-gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service be very prompt\n",
      "[[0 0 0 ... 0 0 0]]\n",
      "love place\n",
      "[[0 0 0 ... 0 0 0]]\n",
      "Logistic regression accuracy: 0.5833333333333334\n",
      "Accuracy of Naive Bayes Classifier with Gaussian prior: 0.7233333333333334\n",
      "Accuracy of Naive Bayes Classifier with Bernoulli prior: 0.45\n",
      "count(yummy tummy) = 5177\n",
      "count(yummy have) = 5176\n",
      "count(yum yum) = 5175\n",
      "count(yum sauce) = 5174\n",
      "count(yukon gold) = 5173\n",
      "count(yet say) = 5172\n",
      "count(yet run) = 5171\n",
      "count(yet delicious) = 5170\n",
      "count(yelper husband) = 5169\n",
      "count(yellowtail carpaccio) = 5168\n",
      "The top 10 most important 2-gram words: \n",
      "['yummy tummy', 'yummy have', 'yum yum', 'yum sauce', 'yukon gold', 'yet say', 'yet run', 'yet delicious', 'yelper husband', 'yellowtail carpaccio']\n"
     ]
    }
   ],
   "source": [
    "# Vectorize with 2-gram model\n",
    "train_vectorizer_2gram = CountVectorizer(ngram_range=(2, 2))\n",
    "# build a dictionary of unique words for training set\n",
    "train_x_2gram = train_vectorizer_2gram.fit_transform(train_x).todense()\n",
    "test_vectorizer_2gram = CountVectorizer(ngram_range=(2, 2), vocabulary=train_vectorizer_2gram.get_feature_names())\n",
    "test_x_2gram = test_vectorizer_2gram.fit_transform(test_x).todense()\n",
    "# Report feature vectors of 2 reviews\n",
    "print(train_x[10])\n",
    "print(train_x_2gram[10])\n",
    "print(train_x[0])\n",
    "print(train_x_2gram[0])\n",
    "\n",
    "# post-processing\n",
    "train_x_2gram_normal = normalize(train_x_2gram)\n",
    "test_x_2gram_normal = normalize(test_x_2gram)\n",
    "\n",
    "sentiment_prediction(train_x_2gram_normal, train_y, test_x_2gram_normal, test_y)\n",
    "# # Logistic regression\n",
    "# lr_clf_2gram = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(train_x_2gram_normal, train_y)\n",
    "# lr_clf_2gram_score = lr_clf_2gram.score(test_x_2gram_normal, test_y)\n",
    "# print(\"Logistic regression accuracy: {}\".format(lr_clf_2gram_score))\n",
    "\n",
    "# # Naive Bayes classifier\n",
    "# # Gaussian\n",
    "# gaussian_nb_2gram = GaussianNB()\n",
    "# gaussian_nb_2gram.fit(train_x_2gram_normal, train_y)\n",
    "# gaussian_nb_2gram_score = gaussian_nb_2gram.score(test_x_2gram_normal, test_y)\n",
    "# print(\"Accuracy of Naive Bayes Classifier with Gaussian prior: {}\".format(gaussian_nb_2gram_score))\n",
    "\n",
    "# # Bernoulli\n",
    "# b_nb_2gram = BernoulliNB()\n",
    "# b_nb_2gram.fit(train_x_2gram_normal, train_y)\n",
    "# b_nb_2gram_score = b_nb_2gram.score(test_x_2gram_normal, test_y)\n",
    "# print(\"Accuracy of Naive Bayes Classifier with Bernoulli prior: {}\".format(b_nb_2gram_score))\n",
    "\n",
    "# Most important 2-gram words\n",
    "vocabulary_2gram = train_vectorizer_2gram.vocabulary_\n",
    "sorted_vocabulary_2gram = sorted(vocabulary_2gram.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "important_words = []\n",
    "for word in sorted_vocabulary_2gram[:10]:\n",
    "    important_words.append(word[0])\n",
    "    print(\"count({}) = {}\".format(word[0], word[1]))\n",
    "\n",
    "print(\"The top 10 most important 2-gram words: \")\n",
    "print(important_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (h) PCA for bag of words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use SVD to peform PCA\n",
    "p,n = np.shape(train_x_bag_normal)\n",
    "cov_Mat = np.dot(train_x_bag_normal.T, train_x_bag_normal)/(p-1)\n",
    "u, s, vh = np.linalg.svd(cov_Mat, full_matrices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression accuracy: 0.5633333333333334\n",
      "Accuracy of Naive Bayes Classifier with Gaussian prior: 0.5633333333333334\n",
      "Accuracy of Naive Bayes Classifier with Bernoulli prior: 0.39\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5633333333333334, 0.5633333333333334, 0.39)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_10 = np.dot(train_x_bag_normal, u[:,:10])\n",
    "test_y_10 = np.dot(test_x_bag_normal, u[:,:10])\n",
    "sentiment_prediction(train_x_10, train_y, test_x_10, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression accuracy: 0.5\n",
      "Accuracy of Naive Bayes Classifier with Gaussian prior: 0.5333333333333333\n",
      "Accuracy of Naive Bayes Classifier with Bernoulli prior: 0.43\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5, 0.5333333333333333, 0.43)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_50 = np.dot(train_x_bag_normal, u[:,:50])\n",
    "test_y_50 = np.dot(test_x_bag_normal, u[:,:50])\n",
    "sentiment_prediction(train_x_50, train_y, test_x_50, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression accuracy: 0.5033333333333333\n",
      "Accuracy of Naive Bayes Classifier with Gaussian prior: 0.5\n",
      "Accuracy of Naive Bayes Classifier with Bernoulli prior: 0.44\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5033333333333333, 0.5, 0.44)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_100 = np.dot(train_x_bag_normal, u[:,:100])\n",
    "test_y_100 = np.dot(test_x_bag_normal, u[:,:100])\n",
    "sentiment_prediction(train_x_100, train_y, test_x_100, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def meanX(dataX):\n",
    "    return np.mean(dataX, axis=0)\n",
    "def pca(XMat, k):\n",
    "    average = meanX(XMat) \n",
    "    m, n = np.shape(XMat)\n",
    "    data_adjust = []\n",
    "    avgs = np.tile(average, (m, 1))\n",
    "    data_adjust = XMat - avgs\n",
    "    covX = np.cov(data_adjust.T)\n",
    "    featValue, featVec=  np.linalg.eig(covX)\n",
    "    index = np.argsort(-featValue)\n",
    "    finalData = []\n",
    "    if k > n:\n",
    "        print(\"k must lower than feature number\")\n",
    "        return\n",
    "    else:\n",
    "        selectVec = np.matrix(featVec.T[index[:k]])\n",
    "        finalData = data_adjust * selectVec.T \n",
    "        reconData = (finalData * selectVec) + average  \n",
    "        finalData = finalData.astype('float64')\n",
    "    return finalData, reconData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Andrea/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:20: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression accuracy: 0.4666666666666667\n",
      "Accuracy of Naive Bayes Classifier with Gaussian prior: 0.5\n",
      "Accuracy of Naive Bayes Classifier with Bernoulli prior: 0.42333333333333334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4666666666666667, 0.5, 0.42333333333333334)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use pca of sklearn first, then switch back to our own PCA function\n",
    "# from sklearn.decomposition import PCA\n",
    "# pca_10 = PCA(n_components=10)\n",
    "# train_x_10 = pca_10.fit_transform(train_x_bag_normal)\n",
    "# test_x_10 = pca_10.fit_transform(test_x_bag_normal)\n",
    "\n",
    "train_x_10, _recon_train = pca(train_x_bag_normal, 10)\n",
    "test_x_10, _recon_test = pca(test_x_bag_normal, 10)\n",
    "sentiment_prediction(train_x_10, train_y, test_x_10, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Andrea/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:20: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression accuracy: 0.43666666666666665\n",
      "Accuracy of Naive Bayes Classifier with Gaussian prior: 0.47\n",
      "Accuracy of Naive Bayes Classifier with Bernoulli prior: 0.44666666666666666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.43666666666666665, 0.47, 0.44666666666666666)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCA with 50 components\n",
    "# pca_50 = PCA(n_components=50)\n",
    "# train_x_50 = pca_50.fit_transform(train_x_bag_normal)\n",
    "# test_x_50 = pca_50.fit_transform(test_x_bag_normal)\n",
    "train_x_50, _recon_train = pca(train_x_bag_normal, 50)\n",
    "test_x_50, _recon_test = pca(test_x_bag_normal, 50)\n",
    "sentiment_prediction(train_x_50, train_y, test_x_50, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Andrea/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:20: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression accuracy: 0.44666666666666666\n",
      "Accuracy of Naive Bayes Classifier with Gaussian prior: 0.5266666666666666\n",
      "Accuracy of Naive Bayes Classifier with Bernoulli prior: 0.43666666666666665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.44666666666666666, 0.5266666666666666, 0.43666666666666665)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCA with 100 components\n",
    "# pca_100 = PCA(n_components=100)\n",
    "# train_x_100 = pca_100.fit_transform(train_x_bag_normal)\n",
    "# test_x_100 = pca_100.fit_transform(test_x_bag_normal)\n",
    "train_x_100, _recon_train = pca(train_x_bag_normal, 100)\n",
    "test_x_100, _recon_test = pca(test_x_bag_normal, 100)\n",
    "sentiment_prediction(train_x_100, train_y, test_x_100, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (i) Algorithm comparison and analysis\n",
    "1) Bag of words using logistic regression performs best. The accuracy is 0.78. It might be because bag of words reserved all features of words and single word could represent features better. <br/>\n",
    "2) The words such as \"yummy\", \"delicious\" plays important role in representing sentiment users' attitudes in comments. <br/>\n",
    "3) The reason that PCA did not work well for this dataset might be because:\n",
    "  * The word features are relatively evenly distributed in all features, which means the directions with highest variance cannot represent most information of the original dataset. So reducing dimensions will lose considerable part of original information. \n",
    "  * Originally the dataset has around 2000 features. Reducing them to ~100 features reduced too much information.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lowercase\n",
    "yelp_sentance = [x.lower() for x in yelp_sentance]\n",
    "amazon_sentance = [x.lower() for x in amazon_sentance]\n",
    "imdb_sentance = [x.lower() for x in imdb_sentance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Strip punctuation\n",
    "yelp_word_vectors = [re.compile('\\w+').findall(x) for x in yelp_sentance]\n",
    "amazon_word_vectors = [re.compile('\\w+').findall(x) for x in amazon_sentance]\n",
    "imdb_word_vectors = [re.compile('\\w+').findall(x) for x in imdb_sentance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/wrymax/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#strip the stop words\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "wordnet_lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "# stop_words.remove('not')\n",
    "yelp_no_stopwords = [list(set(vector) - stop_words) for vector in yelp_word_vectors]\n",
    "amazon_no_stopwords = [list(set(vector) - stop_words) for vector in amazon_word_vectors]\n",
    "imdb_no_stopwords = [list(set(vector) - stop_words) for vector in imdb_word_vectors]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

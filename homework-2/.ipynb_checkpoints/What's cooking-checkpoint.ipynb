{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. import packages\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. read data from json\n",
    "with open('cooking/train.json') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "with open('cooking/test.json') as f:\n",
    "    test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique cuisines: 20\n",
      "unique ingredients: 6714\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "3. Get these metrics:\n",
    "dishes_count:integer\n",
    "cuisine:integer\n",
    "ingredients:list\n",
    "ingredients_count:integer\n",
    "\"\"\"\n",
    "\n",
    "dishes_count = len(train_data)\n",
    "cuisines = set([])\n",
    "ingredients = set([])\n",
    "\n",
    "for i in train_data:\n",
    "    cuisines.add(i['cuisine'])\n",
    "    ingredients |= set(i['ingredients'])\n",
    "cuisines = list(cuisines)\n",
    "ingredients = list(ingredients)\n",
    "cuisines_count = len(cuisines)\n",
    "ingredients_count = len(ingredients)\n",
    "\n",
    "print(\"unique cuisines: {}\".format(cuisines_count))\n",
    "print(\"unique ingredients: {}\".format(ingredients_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x: (39774, 6714)\n",
      "train_y: (39774,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "4. Represent sample data in a n by d matrix, in which n == sample_numbers, d == unique_ingredients_count.\n",
    "Mark the element as 1 if the sample has this ingredient.\n",
    "\"\"\"\n",
    "train_x = np.zeros([dishes_count, ingredients_count])\n",
    "train_y = np.zeros(dishes_count)\n",
    "\n",
    "for i, dish in enumerate(train_data):\n",
    "    for j in dish['ingredients']:\n",
    "        train_x[i][ingredients.index(j)] = 1\n",
    "    train_y[i] = cuisines.index(dish['cuisine'])\n",
    "\n",
    "print(\"train_x: {}\".format(train_x.shape))\n",
    "# print(\"train_x: {}\".format(train_x))\n",
    "print(\"train_y: {}\".format(train_y.shape))\n",
    "# print(\"train_y: {}\".format(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- GaussianNB ----\n",
      "0.37901644290239855\n",
      "---- BernoulliNB ----\n",
      "0.684190677326897\n",
      "---- GaussianNB ----\n",
      "0.3829386031075577\n",
      "---- BernoulliNB ----\n",
      "0.6795142555438226\n",
      "---- GaussianNB ----\n",
      "0.37758334590435966\n",
      "---- BernoulliNB ----\n",
      "0.6869060190073918\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "5. \n",
    "Naive Bayes Classifier using 3-fold cross validation and:\n",
    "1) Gaussian distribution prior assumptions\n",
    "2) Bernuolli distribution prior assumptions\n",
    "\n",
    "\"\"\"\n",
    "gaussian_avg_accuracies = []\n",
    "bernoulli_avg_accuracies = []\n",
    "kf = KFold(n_splits=3)\n",
    "kf.get_n_splits(train_x)\n",
    "for train_index, test_index in kf.split(train_x):\n",
    "    X_train, X_test = train_x[train_index], train_x[test_index]\n",
    "    Y_train, Y_test = train_y[train_index], train_y[test_index]\n",
    "    print(\"---- GaussianNB ----\")\n",
    "    gaussian = GaussianNB()    \n",
    "    gaussian.fit(X_train, Y_train)\n",
    "    g_score = gaussian.score(X_test, Y_test)\n",
    "    gaussian_avg_accuracies.append(g_score)\n",
    "    print(g_score)\n",
    "    print(\"---- BernoulliNB ----\")\n",
    "    bernoulli = BernoulliNB()\n",
    "    bernoulli.fit(X_train, Y_train)\n",
    "    b_score = bernoulli.score(X_test, Y_test)\n",
    "    bernoulli_avg_accuracies.append(b_score)\n",
    "    print(b_score)\n",
    "    \n",
    "print(\"Average accuracy of Gassian Naive Bayes: {}\".format(np.average(gaussian_avg_accuracies)))\n",
    "print(\"Average accuracy of Bermoulli Naive Bayes: {}\".format(np.average(bernoulli_avg_accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "6. Discuss the performance of Gaussian prior and Bernuolli prior\n",
    "\"\"\"\n",
    "# TODO: figure out key metrics to discuss\n",
    "\"\"\"\n",
    "Analysis:\n",
    "By doing 3-fold cross-validations on training set:\n",
    "1. Gaussian Naive Bayes got average accuracy of 0.38\n",
    "2. Bernoulli Naive Bayes got average accuracy of 0.68\n",
    "Bernoulli Naive Bayes performs much better in this case, because features of ingredients have \"existing\" or \"non-existing\" status.\n",
    "So Bernoulli could better describe the probability distribution of the features. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Logistic Regression ----\n",
      "0.7725147081007694\n",
      "---- Logistic Regression ----\n",
      "0.7704782018403983\n",
      "---- Logistic Regression ----\n",
      "0.7757580328858048\n",
      "Average accuracy of logistic regression: 0.772916980942\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "7. Try logistic regression on the training data. Report the average accuracy.\n",
    "\"\"\"\n",
    "logistic_accuracies = []\n",
    "# kf = KFold(n_splits=3)\n",
    "# kf.get_n_splits(train_x)\n",
    "for train_index, test_index in kf.split(train_x):\n",
    "    X_train, X_test = train_x[train_index], train_x[test_index]\n",
    "    Y_train, Y_test = train_y[train_index], train_y[test_index]\n",
    "    print(\"---- Logistic Regression ----\")\n",
    "    clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(X_train, Y_train)\n",
    "    score = clf.score(X_test, Y_test)\n",
    "    logistic_accuracies.append(score)\n",
    "    print(score)\n",
    "logistic_avg_accuracy = np.average(logistic_accuracies)\n",
    "print(\"Average accuracy of logistic regression: {}\".format(logistic_avg_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "8. Train the best-performed classifier and submit the labels to Kaggle.\n",
    "\"\"\"\n",
    "# Prepare for test data\n",
    "test_x = np.zeros([len(test_data), ingredients_count])\n",
    "\n",
    "for i, dish in enumerate(test_data):\n",
    "    for j in dish['ingredients']:\n",
    "        if j in ingredients:\n",
    "            test_x[i][ingredients.index(j)] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers, not numpy.float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3e1b808ef0d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclf_logistic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multinomial'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mp_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_logistic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mingredients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-3e1b808ef0d6>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclf_logistic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multinomial'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mp_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_logistic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mingredients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers, not numpy.float64"
     ]
    }
   ],
   "source": [
    "# Use logistic regression\n",
    "clf_logistic = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(train_x, train_y)\n",
    "p_indices = clf_logistic.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = [['id', 'cuisine']]\n",
    "for i in range(len(test_x)):\n",
    "#     r = \"{},{}\".format(test_data[i]['id'], cuisines[int(p_indices[i])])\n",
    "#     print(r)\n",
    "    ret.append([test_data[i]['id'], cuisines[int(p_indices[i])]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(ret)\n",
    "df.to_csv('./output.csv', header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
